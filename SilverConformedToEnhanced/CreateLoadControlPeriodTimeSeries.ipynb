{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "19b73927-401d-43a6-b8d5-88faf8bc01c2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Create Load Control Time Series\n",
    "Transforms the index load control values into a time series.  This makes it straightforward to join with the meter data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b177a404-6b39-41d0-b1eb-abdea4d22bb2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ../Utilities/ConfigUtilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "52c011a2-07ec-4260-923d-20e170e09f10",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import concat_ws, lit, col, when\n",
    "import pandas as pd\n",
    "\n",
    "debug = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f805c2e7-7291-42ac-94ed-1fa9a97d1a73",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Read the indexed load control periods.\n",
    "lc_df = spark.read.format(\"delta\").load(LOAD_CONTROL_INDEX_PATH)\n",
    "\n",
    "if debug:\n",
    "    display(lc_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c3ca5dd5-0d17-45ae-ba53-b4ff0e094eaa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Create time series data set with the following steps:\n",
    "- Subset down to ID, start index, end index.\n",
    "- Loop through each event to create a time series dataframe with the meter indexes.\n",
    "- Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4b96dc26-8a0d-4d95-8fa8-45f5f5470f32",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Offset the time period from the actual start / stop index for the load control period.  Since the calendar is based on 5 minute intervals, there are 12 indices / hour.\n",
    "# This offseting could take multiple forms:\n",
    "#   - If simply targeting the load control period, then offset the start by +1 (to avoid an issue with join of the end sample) and the end by 0.\n",
    "#   - If you want to avoid the ramp up/down within the load control period, then offset the start by a positive number and the end by a negative number.\n",
    "#   - If you want data points before and after the load control period, then offset the start by a negative number and the end by a positive number.\n",
    "lc_sub_df = lc_df.select('LoadControlEventID', 'ResourceName', 'StartMeterSampleIndex', 'EndMeterSampleIndex')\n",
    "\n",
    "start_offset = -48  # 4 hours\n",
    "end_offset = 48     # 4 hours\n",
    "lc_sub_df = lc_sub_df.withColumn('StartOffsetIndex', col('StartMeterSampleIndex') + start_offset) \\\n",
    "                        .withColumn('EndOffsetIndex', col('EndMeterSampleIndex') + end_offset)\n",
    "\n",
    "if debug:\n",
    "    display(lc_sub_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f70382e6-7538-4384-93ba-be30b33b68d4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# The data is not that big. so let's do this in Pandas.\n",
    "lc_sub_pdf = lc_sub_df.toPandas()\n",
    "\n",
    "if debug:\n",
    "    display(lc_sub_pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "596af2c8-6d66-4f53-b8f9-9e3b280266bc",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": null,
       "filterBlob": "{\"version\":1,\"filterGroups\":[],\"syncTimestamp\":1749837211012}",
       "queryPlanFiltersBlob": "[]",
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create a target dataset.\n",
    "lc_sub_ts_pdf = pd.DataFrame(columns=['LoadControlEventID', 'ResourceName', 'MeterSampleIndex'])\n",
    "\n",
    "#for i in range(0, 2):\n",
    "for i in range(0, lc_sub_pdf.shape[0]):\n",
    "    start_index = lc_sub_pdf.loc[i, 'StartOffsetIndex']\n",
    "    stop_index = lc_sub_pdf.loc[i, 'EndOffsetIndex']\n",
    "    lc_cal_temp_pdf = pd.DataFrame(columns=['LoadControlEventID', 'ResourceName', 'MeterSampleIndex'])\n",
    "    lc_cal_temp_pdf['MeterSampleIndex'] = range(start_index, stop_index+1)\n",
    "    lc_cal_temp_pdf['LoadControlEventID'] = lc_sub_pdf.loc[i, 'LoadControlEventID']\n",
    "    lc_cal_temp_pdf['ResourceName'] = lc_sub_pdf.loc[i, 'ResourceName']\n",
    "    print(lc_sub_pdf.loc[i, 'LoadControlEventID'])  \n",
    "\n",
    "    if (lc_sub_pdf.loc[i, 'LoadControlEventID'] == \"LREC.IRR_2025-06-02 16:00:00_2025-06-02 20:00:00\"):\n",
    "        print(\"Found it\")\n",
    "        print(lc_sub_pdf.loc[i, 'LoadControlEventID'])  \n",
    "        print(str(i))\n",
    "\n",
    "    lc_sub_ts_pdf = pd.concat([lc_sub_ts_pdf, lc_cal_temp_pdf])\n",
    "    i = i+1\n",
    "\n",
    "display(lc_sub_ts_pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e3bcb5bd-1735-4cb2-80e8-37a980b7ed1b",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": null,
       "filterBlob": "{\"version\":1,\"filterGroups\":[],\"syncTimestamp\":1749847020214}",
       "queryPlanFiltersBlob": "[]",
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Convert pandas back to Spark dataframe.\n",
    "lc_sub_ts_df = spark.createDataFrame(lc_sub_ts_pdf)\n",
    "\n",
    "if debug:\n",
    "    print(lc_sub_ts_df.count())\n",
    "    display(lc_sub_ts_df)\n",
    "    display(lc_sub_ts_df.filter(col('LoadControlEventID') == \"LREC.IRR_2025-06-02 16:00:00_2025-06-02 20:00:00\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b9ba22f2-4e28-4495-a4f4-3db143d53216",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "lc_sub_lc_ts_df = lc_sub_ts_df.join(lc_sub_df, on='LoadControlEventID', how='inner')\n",
    "\n",
    "if debug:\n",
    "    display(lc_sub_lc_ts_df.filter(col('StartMeterSampleIndex').isNull()))\n",
    "    display(lc_sub_lc_ts_df.filter(col('LoadControlEventID') == \"LREC.IRR_2025-06-02 16:00:00_2025-06-02 20:00:00\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a78f97af-201d-4528-ba59-293c880373b0",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": null,
       "filterBlob": "{\"version\":1,\"filterGroups\":[{\"enabled\":true,\"op\":\"OR\",\"filterGroupId\":\"fg_c107573e\",\"filters\":[{\"filterId\":\"f_6bf18599\",\"columnId\":\"ResourceName\",\"enabled\":true,\"dataType\":\"string\",\"filterType\":\"oneof\",\"filterConfig\":{}}],\"local\":false,\"updatedAt\":1749836949594},{\"enabled\":true,\"op\":\"OR\",\"filterGroupId\":\"fg_7a45c4ac\",\"filters\":[{\"filterId\":\"f_76c10dfc\",\"columnId\":\"ResourceName\",\"enabled\":true,\"dataType\":\"string\",\"filterType\":\"oneof\",\"filterConfig\":{}}],\"local\":false,\"updatedAt\":1749836968890}],\"syncTimestamp\":1749837967734}",
       "queryPlanFiltersBlob": "[]",
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Identify intervals that are within the load control period.  Steps to do this:\n",
    "#   - Join the load control time series with the original data containing the start / stop index.\n",
    "#   - Add a LoadControlEvent flag (1) to all indices within the start / stop index.\n",
    "#   - Remove the extra columns.\n",
    "lc_sub_df = lc_df.select('LoadControlEventId', 'StartMeterSampleIndex', 'EndMeterSampleIndex')\n",
    "lc_sub_lc_ts_df = lc_sub_ts_df.join(lc_sub_df, on='LoadControlEventID', how='inner')\n",
    "\n",
    "lc_sub_lc_ts_df = lc_sub_lc_ts_df.withColumn('LoadControlEvent', \n",
    "                                when(\n",
    "                                    (col('MeterSampleIndex') > col('StartMeterSampleIndex')) & \n",
    "                                    (col('MeterSampleIndex') <= col('EndMeterSampleIndex')), \n",
    "                                lit(1)\n",
    "                                ).otherwise(lit(0)) )\n",
    "\n",
    "if debug:\n",
    "    display(lc_sub_lc_ts_df)\n",
    "    display(lc_sub_lc_ts_df.filter(col('LoadControlEventID') == \"LREC.IRR_2025-06-02 16:00:00_2025-06-02 20:00:00\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "922bcd9c-b105-4bce-85c1-0a5adc4e0e6d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Drop the extra columns.\n",
    "lc_sub_lc_ts_df = lc_sub_lc_ts_df.drop('StartMeterSampleIndex', 'EndMeterSampleIndex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a5a2e4a2-1b3b-4357-943e-acf9f0244b41",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Save the data to the silver enhanced tier\n",
    "lc_sub_lc_ts_df.write.mode('overwrite').parquet(LOAD_CONTROL_TIMESERIES_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "50795034-ab7e-4c64-8209-93d1f5d0e01d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Vacuum\n",
    "spark.sql(f\"VACUUM '{LOAD_CONTROL_TIMESERIES_PATH}'\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "CreateLoadControlPeriodTimeSeries",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
