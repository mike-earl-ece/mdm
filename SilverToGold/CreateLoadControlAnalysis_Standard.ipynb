{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3b60e455-5a44-4b43-a73a-72a715111acc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Create Load Control Analysis\n",
    "\n",
    "This script creates an output time series that can be analyzed in Power BI for improperly functioning load controllers. The output time series has data for every timestamp of a meter during load control event(s).  To be in the dataset, the meter must have all load controllers being controlled.  For example, a meter with dual fuel and water heater controllers on it will only have timestamps in the output dataset when there are load control events controlling both devices.\n",
    "\n",
    "The script incrementally appends the output time series for new load control events that occurred since the last output save.  \n",
    "\n",
    "There are four inputs to this process:\n",
    "- A time series that represents the load control events.  This is created by upstream jobs and updated daily.\n",
    "- A map that ties together load control events and controlled load types. This is manually maintained.\n",
    "- Information for each meter that has one or more controlled loads.  This comes from iVUE and is updated daily.\n",
    "- The full indexed meter data that is updated daily in upstream jobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "64a3442a-3b96-49bb-86b8-afa10a9d0926",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ../../Utilities/ConfigUtilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6a962424-450a-4ea4-a277-159b4a23b7f8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import IntegerType, StructType, StructField, StringType\n",
    "from pyspark.sql.functions import max, min, count, when, sum, concat_ws, col, to_timestamp, lit\n",
    "from delta.tables import *\n",
    "\n",
    "debug = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "801c7d78-9c85-4b27-96d7-fff6ac7fe53c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Get the load control, event to type map, and meter information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c31bb231-944c-4875-9ee3-f32d5e7409d0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# To incrementally update the output table, we need to find the last load control event that has been processed.\n",
    "try:\n",
    "    lc_df_iwh_df = DeltaTable.forPath(spark, LOAD_CONTROL_METERTS_PATH).toDF()\n",
    "    last_processed_index = lc_df_iwh_df.select(max('EndMeterSampleIndex')).collect()[0][0]\n",
    "except:   # Table is empty\n",
    "    last_processed_index= 1\n",
    "\n",
    "if debug:\n",
    "    print(last_processed_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4478a14b-f44f-449f-8eed-c4f57007fd05",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": null,
       "filterBlob": "{\"version\":1,\"filterGroups\":[],\"syncTimestamp\":1749847379838}",
       "queryPlanFiltersBlob": "[]",
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Get the load control time series and filter to the new events.\n",
    "lc_ts_df = spark.read.parquet(LOAD_CONTROL_TIMESERIES_PATH)\n",
    "\n",
    "lc_new_ts_df = lc_ts_df.filter(lc_ts_df.MeterSampleIndex > last_processed_index)\n",
    "\n",
    "if lc_new_ts_df.count() == 0:\n",
    "    dbutils.notebook.exit(\"No new load control periods found.\") \n",
    "\n",
    "if debug:\n",
    "    display(lc_new_ts_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2b544e66-9906-445e-b493-00ce33e5211c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Read the program to meter map data.\n",
    "meter_control_event_types_df = spark.read.format('delta'). load(LOAD_CONTROL_METER_PROGRAM_MAP_PATH)\n",
    "\n",
    "if debug:\n",
    "    display(meter_control_event_types_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "498e661f-d620-49d0-8b3c-5c56b0c7cdb5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Update the load control time series with the meter information.  \n",
    "This involves ensuring that all controlled loads for a meter are being controlled. This analysis won't be of value for partial control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b018d365-6354-4160-8734-2850c68f81b2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Join the load control time series with the meter info.\n",
    "lc_meter_ts_df = lc_new_ts_df.join(meter_control_event_types_df, on='ResourceName', how='inner')\n",
    "\n",
    "if debug:\n",
    "    display(lc_meter_ts_df)\n",
    "    display(lc_meter_ts_df.filter(col('BI_MTR_NBR') == 65918693))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "acde2795-5a2f-4067-8476-c1c3efc2dca2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Eliminate meters that don't have all load types being controlled for any MeterSampleIndex.\n",
    "\n",
    "# Get the meters.\n",
    "lc_meter_ts_dups_df = lc_meter_ts_df.groupBy('MeterSampleIndex', 'BI_MTR_NBR').agg(count('BI_LOAD_TYPE').alias('Count'))\n",
    "\n",
    "if debug:\n",
    "    display(lc_meter_ts_dups_df)\n",
    "    display(lc_meter_ts_dups_df.filter(col('BI_MTR_NBR') == 65918693))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "809c0d72-a047-41f8-9d93-bab711b336c5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Get the program count for each meter.\n",
    "meter_control_program_count_df = meter_control_event_types_df.groupBy('BI_MTR_NBR').agg(count('BI_LOAD_TYPE').alias('ProgramCount'))\n",
    "\n",
    "if debug:\n",
    "    display(meter_control_program_count_df)\n",
    "    display(meter_control_program_count_df.filter(col('BI_MTR_NBR') == 65918693))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a7be6e68-d6b1-4cf4-8449-f665c76a75c9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Join the duplicate count from the load control time series with the program count dataframe for each meter.  \n",
    "meter_control_program_diff_df = meter_control_program_count_df.join(lc_meter_ts_dups_df, on='BI_MTR_NBR', how='inner')\n",
    "\n",
    "# Create a new column to compare program count with instance count.\n",
    "meter_control_program_diff_df = meter_control_program_diff_df.withColumn('ProgramDiff', col('ProgramCount') - col('Count'))\n",
    "\n",
    "if debug:\n",
    "    display(meter_control_program_diff_df)\n",
    "    display(meter_control_program_diff_df.groupBy('ProgramDiff').agg(count('BI_MTR_NBR').alias('MeterCount')))\n",
    "    display(meter_control_program_diff_df.filter(col('BI_MTR_NBR') == 65918693))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "26235797-948f-4c26-86e7-38d6ffd871ac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Filter down to meter samples that are fully fulfilled and join with the load control time series to restrict it.\n",
    "meter_control_program_fullfilled_df = meter_control_program_diff_df.filter(col('ProgramDiff') == 0).select('BI_MTR_NBR', 'MeterSampleIndex')\n",
    "\n",
    "lc_meter_fullfilled_ts_df = lc_meter_ts_df.join(meter_control_program_fullfilled_df, on=['BI_MTR_NBR', 'MeterSampleIndex'], how='inner')\n",
    "\n",
    "if debug:\n",
    "    display(lc_meter_fullfilled_ts_df)\n",
    "    display(lc_meter_fullfilled_ts_df.filter(col('BI_MTR_NBR') == 65918693))\n",
    "    print(\"All load control time series data points: \" + str(lc_meter_ts_df.count())) \n",
    "    print(\"Fulfilled load control time series data points: \" + str(lc_meter_fullfilled_ts_df.count())) \n",
    "                                                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "80e12d61-9e31-48d7-a48b-e0b3be95184d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "if debug:\n",
    "    display(lc_meter_ts_df.filter(col('BI_MTR_NBR') == 65918693 ))\n",
    "    display(lc_meter_fullfilled_ts_df.filter(col('BI_MTR_NBR') == 65918693 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e73f6026-e571-4cdf-ab4e-e1b35b23a270",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Subset dataframe before the join. The distinct() shouldn't be needed, but included to avoid dupicates.\n",
    "lc_meter_fullfilled_min_ts_df = lc_meter_fullfilled_ts_df.select('BI_ACCT', 'BI_SRV_LOC_NBR', 'BI_MTR_NBR', 'MeterSampleIndex', 'LoadControlEventID', 'BI_LOAD_TYPE', 'LoadControlEvent').distinct()\n",
    "\n",
    "if debug:\n",
    "    display(lc_meter_fullfilled_min_ts_df)\n",
    "    display(lc_meter_fullfilled_min_ts_df.filter(col('BI_MTR_NBR') == 65918693 ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a235459a-208c-43f7-9816-9e889f234b15",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Read the meter data and join \n",
    "The meter data is joined with the meters / samples that represent fulfilled programs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0d4d4d69-18c0-4a4f-beac-7e71e74911f0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Read the meter data\n",
    "meter_data_df = DeltaTable.forPath(spark, MDM_INDEXED_PATH).toDF()\n",
    "\n",
    "# Filter out old data to simplify the next join.  ALso limit to forward flow and channel 1\n",
    "first_lc_meter_sample_index = lc_meter_fullfilled_min_ts_df.select(min(col('MeterSampleIndex'))).collect()[0][0]\n",
    "meter_data_df = meter_data_df.filter((col('EndMeterSampleIndex') >= first_lc_meter_sample_index) \n",
    "                                     & (col('FlowDirection') == 'F') & (col('Channel') == 1))\n",
    "\n",
    "# If no new data, exit.\n",
    "if meter_data_df.count() == 0:\n",
    "    dbutils.notebook.exit(\"No new data found.\") \n",
    "\n",
    "if debug:\n",
    "    print(first_lc_meter_sample_index)\n",
    "    display(meter_data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a8674c01-ce92-4451-89e5-3d5bc1ebcc99",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Join the meter data with the distinct indexes / meters in the load control time series.\n",
    "load_control_df = meter_data_df.join(lc_meter_fullfilled_min_ts_df, \\\n",
    "                            (meter_data_df.EndMeterSampleIndex==lc_meter_fullfilled_min_ts_df.MeterSampleIndex) & \\\n",
    "                            (meter_data_df.MeterNumber==lc_meter_fullfilled_min_ts_df.BI_MTR_NBR), how='inner')\n",
    "\n",
    "if debug:\n",
    "    print(load_control_df.count())\n",
    "    display(load_control_df)\n",
    "    display(load_control_df.filter(col('BI_MTR_NBR') == 65918693 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7ef47c12-a900-4a41-835f-0fa63474acf7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(load_control_df.filter(col('BI_MTR_NBR') == 12151219))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6aff65ec-ee8f-416a-b57c-e5fc8940c0b6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Clean up the dataframe.\n",
    "load_control_df = load_control_df.select('BI_ACCT', 'BI_SRV_LOC_NBR', 'MeterNumber', 'UnitOfMeasure', 'FlowDirection', 'Channel', 'StartDateTime', 'EndDateTime', 'StartMeterSampleIndex', 'EndMeterSampleIndex', 'AMIValue', 'VEEValue', 'LoadControlEventId', 'BI_LOAD_TYPE', 'LoadControlEvent') \n",
    "\n",
    "if debug:\n",
    "    display(load_control_df)\n",
    "    display(load_control_df.filter((col('BI_MTR_NBR') == 65918693)))\n",
    "    display(load_control_df.filter(col('BI_MTR_NBR') == 12151219))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bd42e6f5-dd09-49a3-92fc-077e2515c93f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Aggregate data to hourly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "022c4475-d0f1-4053-a792-1fb62f58eac7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# We need local time and not UTC time for the time series. Get the calendar dataset, subset it, and then join with the load control data.\n",
    "calendar_df = spark.read.format('parquet').load(INDEXED_CALENDAR_PATH)\n",
    "\n",
    "if debug:\n",
    "    # Check on a sample load control window starting at 3:00 PM and ending at 7:00 PM.\n",
    "    display(calendar_df.filter(col('MeterSampleIndex') == 371472))\n",
    "    display(calendar_df.filter(col('MeterSampleIndex') == 371520))\n",
    "\n",
    "    display(calendar_df.filter(col('MeterSampleIndex') == 448902))\n",
    "\n",
    "# Eliminate the UTC time info.\n",
    "calendar_df = calendar_df.select('MeterSampleIndex', 'LocalTimeStamp', 'LocalYear', 'LocalMonth', 'LocalDay', 'LocalHour', 'LocalMinute')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "207e44cd-e40d-457c-a395-4a46c13da889",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Join with the load control dates.  \n",
    "load_control_dates_df = load_control_df.join(calendar_df, load_control_df.StartMeterSampleIndex==calendar_df.MeterSampleIndex, how='inner')\n",
    "\n",
    "if debug:\n",
    "    display(load_control_dates_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3787f345-55aa-4470-a8d1-63d3c56b0ad7",
     "showTitle": false,
     "tableResultSettingsMap": {
      "1": {
       "dataGridStateBlob": null,
       "filterBlob": "{\"version\":1,\"filterGroups\":[{\"enabled\":true,\"filterGroupId\":\"fg_42c205f4\",\"op\":\"OR\",\"filters\":[{\"filterId\":\"f_e587e578\",\"enabled\":true,\"columnId\":\"MeterSampleIndex\",\"dataType\":\"integer\",\"filterType\":\"oneof\"}],\"local\":false,\"updatedAt\":1749848100462}],\"syncTimestamp\":1749848100463}",
       "queryPlanFiltersBlob": "[]",
       "tableResultIndex": 1
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create an HourEnding column.  Since the join was on the start index for all time periods, we can just add an hour.\n",
    "load_control_dates_df = load_control_dates_df.withColumn('HourEnding', col('LocalHour')+1)\n",
    "\n",
    "if debug:\n",
    "    display(load_control_dates_df)\n",
    "    display(load_control_dates_df.filter(col('LoadControlEventID') == \"LREC.IRR_2025-06-02 16:00:00_2025-06-02 20:00:00\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4eed4652-d389-4d37-a0c7-df70dc2ab12e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import sum, first, last\n",
    "\n",
    "# Aggregate to hourly data.\n",
    "load_control_hourly_df = load_control_dates_df.groupBy('BI_ACCT', 'BI_SRV_LOC_NBR', 'MeterNumber', 'UnitOfMeasure', 'FlowDirection', 'Channel', 'LocalYear', 'LocalMonth', 'LocalDay', 'HourEnding', 'LoadControlEventId', 'BI_LOAD_TYPE').agg(\n",
    "    sum(\"AMIValue\").alias(\"HourlyAMIValue\"),\n",
    "    sum(\"VEEValue\").alias(\"HourlyVEEValue\"),\n",
    "    max(\"EndMeterSampleIndex\").alias(\"EndMeterSampleIndex\"), \n",
    "    min(\"LoadControlEvent\").alias(\"LoadControlEvent\"))\n",
    "\n",
    "if debug:\n",
    "    display(load_control_hourly_df)\n",
    "    display(load_control_hourly_df.filter(col('LoadControlEventID') == \"LREC.PSWH8_2025-04-08 05:00:00_2025-04-08 11:30:00\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1a0f5251-95f3-4c00-aa36-3a6424bdd0ba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "if debug:\n",
    "    sample1 = load_control_hourly_df.filter((col('MeterNumber') == 65918693))\n",
    "    display(sample1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1cfa7ab9-72ac-46c7-81db-a5cb8c5ecd43",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Rename the Local time data to match the other data.\n",
    "load_control_hourly_df = load_control_hourly_df.withColumnRenamed('LocalYear', 'Year') \\\n",
    "                                .withColumnRenamed('LocalMonth', 'Month') \\\n",
    "                                    .withColumnRenamed('LocalDay', 'Day') \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "57383909-1ca0-4eb5-939f-71ce86024158",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Append the new data to the existing data.\n",
    "load_control_hourly_df.write.format(\"delta\").mode(\"append\").option(\"mergeSchema\", \"true\").save(LOAD_CONTROL_METERTS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "44274eff-e257-412a-b4cd-2381faf81f6c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Vacuum\n",
    "spark.sql(f\"VACUUM '{LOAD_CONTROL_METERTS_PATH}'\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "CreateLoadControlAnalysis_Standard",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
