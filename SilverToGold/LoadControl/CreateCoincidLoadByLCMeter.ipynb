{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f14b9cfb-ce26-43c3-a899-ee3ad7272c4c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Create Coincident Load By Load Control Meter\n",
    "Finds usage for all meters in a load control program during the GRE monthly coincidental load."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "17d79033-0b3d-4914-bff8-826b1f50ca37",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ../../Utilities/ConfigUtilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "978aed76-bdcb-48fd-a1e5-52242fd04c75",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, concat, lit, sum\n",
    "\n",
    "debug = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9a747780-71cc-4379-95c8-afe16e17735d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Read the coincidental load information with index information.\n",
    "coincid_load_df = spark.read.format(\"delta\").load(COINCIDENTAL_LOAD_INDEX_PATH)\n",
    "\n",
    "if debug:\n",
    "  display(coincid_load_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "48b63090-d7cc-41fb-90ac-a701615945e7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Read the data containing the load control meters and associated programs.\n",
    "load_control_df = spark.read.format(\"delta\").load(LOAD_CONTROL_METER_PROGRAM_MAP_PATH)\n",
    "\n",
    "if debug:\n",
    "    print(load_control_df.count())\n",
    "    display(load_control_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "53f74146-8698-4512-9461-929737f52757",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(load_control_df.filter(col('BI_MTR_NBR') == \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d534422d-5935-4001-aaf6-f63a469b1b74",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import collect_list, concat_ws\n",
    "\n",
    "load_control_df = load_control_df.orderBy(\"BI_MTR_NBR\", \"BI_LOAD_TYPE\")\n",
    "\n",
    "# Group by BI_METER_NBR and concatenate BI_LOAD_TYPE separated by a comma\n",
    "load_control_agg_df = load_control_df.groupBy(\"BI_MTR_NBR\").agg(concat_ws(\",\", collect_list(\"BI_LOAD_TYPE\")).alias(\"BI_LOAD_TYPE_LIST\"), \n",
    "                                                      concat_ws(\",\", collect_list(\"ResourceName\")).alias(\"Program_List\"))\n",
    "\n",
    "if debug:\n",
    "    print(load_control_agg_df.count())\n",
    "    display(load_control_agg_df)\n",
    "    display(load_control_agg_df.filter(col('BI_MTR_NBR') == '65918693'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "060984a4-c57a-4996-bdf6-c46f60040ede",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Read the hourly meter data.\n",
    "hourly_df = spark.read.format(\"delta\").load(MDM_HOURLY_PATH)\n",
    "\n",
    "if debug:\n",
    "    display(hourly_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "efb91f5e-60bd-446a-9e3b-190251c1838e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Filter the hourly data to the coincidental peak hour by joining with the coincidental peak dataframe.\n",
    "hourly_coincid_df = hourly_df.join(coincid_load_df, hourly_df.EndMeterSampleIndex == coincid_load_df.MeterSampleIndex)\n",
    "\n",
    "hourly_coincid_df = hourly_coincid_df.drop('MeterSampleIndex', 'LocalYear', 'LocalMonth', 'LocalDay', 'HourEnding')\n",
    "\n",
    "if debug:\n",
    "    display(hourly_coincid_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d75fac79-88ac-499b-9e29-d3b077caae1b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Get totals for the coincidental peak slot for all meters.\n",
    "hourly_coincid_total_df = hourly_coincid_df.groupBy(\"CoincidYear\", \"CoincidMonth\").agg(sum(\"HourlyAMIValue\").alias(\"TotalCPHourlyAMIValue\"), sum(\"HourlyVEEValue\").alias(\"TotalCPHourlyVEEValue\"))\n",
    "\n",
    "hourly_coincid_total_df = hourly_coincid_total_df.withColumn(\"YearMonth\", concat(hourly_coincid_total_df.CoincidYear, lit(\"-\"), hourly_coincid_total_df.CoincidMonth))\n",
    "\n",
    "if debug:\n",
    "    display(hourly_coincid_total_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "92a5b4ca-34a6-4d93-8043-050e7b8a332f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Save this total for comparison with the GRE total and the load control total.\n",
    "hourly_coincid_total_df.write.format(\"delta\").mode(\"overwrite\").save(COINCIDENTAL_PEAK_ALL_METER_TOTAL_PATH) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8b5f1be6-2b64-415f-9958-df13ff04ddb3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Clean up the delta history.\n",
    "spark.sql(f\"VACUUM '{COINCIDENTAL_PEAK_ALL_METER_TOTAL_PATH}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "60d48898-a790-4f0d-834e-eeab5d92a522",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Filter to the load control meters.\n",
    "hourly_coincid_lc_df = hourly_coincid_df.join(load_control_agg_df, (hourly_coincid_df.MeterNumber == load_control_agg_df.BI_MTR_NBR), how='inner')\n",
    "\n",
    "if debug:\n",
    "    display(hourly_coincid_lc_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "86e25b39-7986-472a-9d06-6620af060118",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "hourly_coincid_lc_df = hourly_coincid_lc_df.withColumn(\"YearMonth\", concat(hourly_coincid_lc_df.CoincidYear, lit(\"-\"), hourly_coincid_lc_df.CoincidMonth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "542c41aa-02c7-402b-848a-6b3f890dab21",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Save to the gold tier.\n",
    "hourly_coincid_lc_df.write.format(\"delta\").mode(\"overwrite\").save(COINCIDENTAL_PEAK_USAGE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d5d6cb3d-6e5a-4680-b5df-285d17356a80",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Clean up the delta history.\n",
    "spark.sql(f\"VACUUM '{COINCIDENTAL_PEAK_USAGE_PATH}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "028c54d4-60fb-4b2e-83c2-3389bcfb701e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create a YearMonth dimension table for use in PowerBI.\n",
    "yearmonth_df = hourly_coincid_lc_df.select(\"CoincidYear\", \"CoincidMonth\", \"YearMonth\").distinct()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2c34ebb5-2d61-4ee9-97c0-37302f881dcb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Join with the demand rates to have them available to all other datasets in PowerBI.  \n",
    "demand_rate_df = spark.read.csv(DEMAND_RATE_PATH, header=True, inferSchema=True)\n",
    "\n",
    "yearmonth_demand_df = yearmonth_df.join(demand_rate_df, yearmonth_df.CoincidMonth == demand_rate_df.Month, how='inner')\n",
    "\n",
    "if debug:\n",
    "    display(yearmonth_demand_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "126352c2-46e3-4aaf-abaa-28d3003076d4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Save\n",
    "yearmonth_demand_df.write.format(\"delta\").mode(\"overwrite\").save(COINCIDENTAL_PEAK_DIM_YEARMONTH_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c13f26ff-67d2-4c2a-9d9c-816522281665",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Clean up the delta history.\n",
    "spark.sql(f\"VACUUM '{COINCIDENTAL_PEAK_DIM_YEARMONTH_PATH}'\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "CreateCoincidLoadByLCMeter",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
