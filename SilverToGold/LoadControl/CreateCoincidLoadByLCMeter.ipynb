{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f14b9cfb-ce26-43c3-a899-ee3ad7272c4c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Create Coincident Load By Load Control Meter\n",
    "Finds usage for all meters in a load control program during the GRE monthly coincidental load."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "17d79033-0b3d-4914-bff8-826b1f50ca37",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ../../Utilities/ConfigUtilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cb3eec94-9b21-4531-81b8-dc28ea5d8852",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Set up the environment using a function in ConfigUtilties.\n",
    "set_spark_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "978aed76-bdcb-48fd-a1e5-52242fd04c75",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, concat, lit, sum, count\n",
    "\n",
    "debug = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9a747780-71cc-4379-95c8-afe16e17735d",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": null,
       "filterBlob": "{\"version\":1,\"filterGroups\":[{\"enabled\":true,\"filterGroupId\":\"fg_75b5886f\",\"op\":\"OR\",\"filters\":[{\"filterId\":\"f_bb6ff481\",\"enabled\":true,\"columnId\":\"BI_LOAD_TYPE\",\"dataType\":\"string\",\"filterType\":\"oneof\",\"filterValues\":[\"SS1\"],\"filterConfig\":{\"caseSensitive\":true}}],\"local\":false,\"updatedAt\":1749905464736}],\"syncTimestamp\":1749905464741}",
       "queryPlanFiltersBlob": "[{\"kind\":\"call\",\"function\":\"or\",\"args\":[{\"kind\":\"call\",\"function\":\"in\",\"args\":[{\"kind\":\"identifier\",\"identifier\":\"BI_LOAD_TYPE\"},{\"kind\":\"literal\",\"value\":\"SS1\",\"type\":\"string\"}]}]}]",
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Read the meter load type information.\n",
    "load_types_df = spark.read.csv(METER_CONTROL_TYPES_PATH, header=True)\n",
    "\n",
    "if debug:\n",
    "  display(load_types_df)\n",
    "  print(load_types_df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "63ada0a2-941d-4ccc-9baf-4f94be7bbcd6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Dig into the meter position 1 programs.  Some of these may not be dedicated meters and should be removed from the CP analysis.\n",
    "lc_pos1_df = load_types_df.filter(col('BI_MTR_POS_NBR') == \"1\").groupBy(\"BI_LOAD_TYPE\", \"BI_LOAD_TYPE_DESC\").agg(count('*').alias(\"MeterCount\")).orderBy(col(\"MeterCount\").desc())\n",
    "\n",
    "display(lc_pos1_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "58bf4a61-7360-432c-a53e-b250cc3a2a5f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Remove position 1 meters in selected load types.  These are either credit accounts or cycled loads that should not be included in the CP analysis.\n",
    "load_types_filter_df = load_types_df.filter(~((col('BI_MTR_POS_NBR') == \"1\") & (col('BI_LOAD_TYPE') == \"CAC\") | (col('BI_LOAD_TYPE') == \"CA1\")))\n",
    "\n",
    "if debug:\n",
    "    print(load_types_filter_df.count())\n",
    "    display(load_types_filter_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d0ddf116-2797-4162-8d99-fdaf9d5b5407",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d534422d-5935-4001-aaf6-f63a469b1b74",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import collect_list, concat_ws\n",
    "\n",
    "load_types_df = load_types_df.orderBy(\"BI_MTR_NBR\", \"BI_LOAD_TYPE\")\n",
    "\n",
    "# Group by BI_METER_NBR and concatenate BI_LOAD_TYPE separated by a comma\n",
    "load_types_agg_df = load_types_df.groupBy(\"BI_MTR_NBR\").agg(concat_ws(\",\", collect_list(\"BI_LOAD_TYPE\")).alias(\"BI_LOAD_TYPE_LIST\"))\n",
    "\n",
    "if debug:\n",
    "    print(load_types_agg_df.count())\n",
    "    display(load_types_agg_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "060984a4-c57a-4996-bdf6-c46f60040ede",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Read the hourly meter data.\n",
    "hourly_df = spark.read.format(\"delta\").load(MDM_HOURLY_PATH)\n",
    "\n",
    "if debug:\n",
    "    display(hourly_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "13203d29-8d5d-4915-94de-7b06a30ebc59",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Read the coincidental peak index data.\n",
    "coincid_peak_df = spark.read.format(\"delta\").load(COINCIDENTAL_LOAD_INDEX_PATH)\n",
    "\n",
    "if debug:\n",
    "    display(coincid_peak_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "efb91f5e-60bd-446a-9e3b-190251c1838e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Filter the hourly data to the coincidental peak hour by joining with the coincidental peak dataframe.\n",
    "hourly_coincid_df = hourly_df.join(coincid_peak_df, hourly_df.EndMeterSampleIndex == coincid_peak_df.MeterSampleIndex)\n",
    "\n",
    "hourly_coincid_df = hourly_coincid_df.drop('MeterSampleIndex', 'LocalYear', 'LocalMonth', 'LocalDay', 'HourEnding')\n",
    "\n",
    "if debug:\n",
    "    display(hourly_coincid_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "60d48898-a790-4f0d-834e-eeab5d92a522",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Filter to the load control meters.\n",
    "hourly_coincid_lc_df = hourly_coincid_df.join(load_types_agg_df, (hourly_coincid_df.MeterNumber == load_types_agg_df.BI_MTR_NBR), how='inner')\n",
    "\n",
    "if debug:\n",
    "    display(hourly_coincid_lc_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "86e25b39-7986-472a-9d06-6620af060118",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "hourly_coincid_lc_df = hourly_coincid_lc_df.withColumn(\"YearMonth\", concat(hourly_coincid_lc_df.CoincidYear, lit(\"-\"), hourly_coincid_lc_df.CoincidMonth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "542c41aa-02c7-402b-848a-6b3f890dab21",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Save to the gold tier.\n",
    "hourly_coincid_lc_df.write.format(\"delta\").mode(\"overwrite\").save(COINCIDENTAL_PEAK_LOADCONTROL_USAGE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d5d6cb3d-6e5a-4680-b5df-285d17356a80",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Clean up the delta history.\n",
    "spark.sql(f\"VACUUM '{COINCIDENTAL_PEAK_LOADCONTROL_USAGE_PATH}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "028c54d4-60fb-4b2e-83c2-3389bcfb701e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create a YearMonth dimension table for use in PowerBI.\n",
    "yearmonth_df = hourly_coincid_lc_df.select(\"CoincidYear\", \"CoincidMonth\", \"YearMonth\").distinct()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2c34ebb5-2d61-4ee9-97c0-37302f881dcb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Join with the demand rates to have them available to all other datasets in PowerBI.  \n",
    "demand_rate_df = spark.read.csv(DEMAND_RATE_PATH, header=True, inferSchema=True)\n",
    "\n",
    "yearmonth_demand_df = yearmonth_df.join(demand_rate_df, yearmonth_df.CoincidMonth == demand_rate_df.Month, how='inner').drop(\"Month\")\n",
    "\n",
    "if debug:\n",
    "    display(yearmonth_demand_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "126352c2-46e3-4aaf-abaa-28d3003076d4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Save\n",
    "yearmonth_demand_df.write.format(\"delta\").mode(\"overwrite\").save(COINCIDENTAL_PEAK_DIM_YEARMONTH_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c13f26ff-67d2-4c2a-9d9c-816522281665",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Clean up the delta history.\n",
    "spark.sql(f\"VACUUM '{COINCIDENTAL_PEAK_DIM_YEARMONTH_PATH}'\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "CreateCoincidLoadByLCMeter",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
